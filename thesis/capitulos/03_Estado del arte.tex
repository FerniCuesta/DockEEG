\chapter{Estado del arte}\label{cap:estado_del_arte}

% [En el estado del arte se necesita hacer un estudio tanto sobre la tecnología que soporta el proyecto como sobre el problema que se aborda en él. Se puede estructurar por secciones y se aconseja utilizar referencias a los documentos e información que se describe aquí.]

% [Como norma general y más en proyectos con carácter investigador, se recomienda añadir un párrafo por cada documento/referencia que estudie del estado del arte, finalizando esta sección con un párrafo explicativo de la novedad/característica que propone, modifica o añade el proyecto sobre dicho estado del arte.]

\section{Computación de alto rendimiento (\acs{HPC})}\label{sec:computacion_alto_rendimiento}

La computación de alto rendimiento (\acs{HPC}) se refiere a la práctica de agregar poder de cómputo para lograr un rendimiento mucho mayor que el que se podría obtener con una computadora convencional, con el objetivo de resolver problemas complejos en ciencias, ingeniería o negocios \cite{sravanthi2014HPC}.

\subsubsection{Objetivos principales de los sistemas \acs{HPC}}

El propósito fundamental de la infraestructura \acs{HPC} es acelerar la resolución de problemas complejos, alcanzando resultados en tiempos factibles que de otra manera requerirían semanas o meses. Para ello, la \acs{HPC} se apoya en dos conceptos centrales: paralelización y escalabilidad.

\paragraph{Paralelización}
La paralelización consiste en descomponer un problema en múltiples tareas que puedan ejecutarse simultáneamente en distintos núcleos de procesamiento, ya sean CPUs o GPUs. Este enfoque permite aprovechar todos los recursos del sistema para reducir significativamente el tiempo de ejecución de las aplicaciones. Existen distintos niveles de paralelización:

\begin{itemize}
    \item \textbf{Paralelización a nivel de instrucción}: el procesador ejecuta varias instrucciones de manera simultánea mediante pipelines y unidades vectoriales.
    \item \textbf{Paralelización a nivel de hilo o thread}: diferentes hilos de ejecución procesan tareas concurrentes dentro de un mismo núcleo o CPU.
    \item \textbf{Paralelización a nivel de proceso o nodo}: tareas completas se distribuyen entre múltiples nodos de un clúster, cada uno con su propio conjunto de recursos.
\end{itemize}
\paragraph{Escalabilidad}
La escalabilidad se refiere a la capacidad de un sistema para mejorar su rendimiento al añadir más recursos de cómputo. Se distingue entre:

\begin{itemize}
    \item \textbf{Escalabilidad fuerte}: mejora del tiempo de ejecución de un problema de tamaño fijo al incrementar el número de recursos.
    \item \textbf{Escalabilidad débil}: capacidad de mantener constante el tiempo de ejecución al aumentar simultáneamente el tamaño del problema y los recursos de manera proporcional.
\end{itemize}

Lograr buena escalabilidad es crítico, especialmente en entornos multinodo, donde la comunicación entre nodos y la sincronización de tareas pueden generar cuellos de botella.

\subsubsection{Arquitecturas comunes en \acs{HPC}}

Los sistemas \acs{HPC} modernos pueden clasificarse en función de su arquitectura:

\begin{itemize}
    \item \textbf{Sistemas homogéneos}: utilizan múltiples CPUs idénticas interconectadas. Esto simplifica la planificación de tareas y el balance de carga, aunque no aprovecha posibles ventajas de eficiencia energética de núcleos especializados.
    \item \textbf{Sistemas heterogéneos}: combinan distintos tipos de núcleos de procesamiento o aceleradores especializados, como GPUs, FPGAs o núcleos de eficiencia energética tipo \textit{big.LITTLE}. Estas arquitecturas permiten un mayor rendimiento por watt y mejor aprovechamiento de recursos, pero requieren técnicas avanzadas de programación y planificación.
    \item \textbf{Clústeres y supercomputadores}: integran múltiples nodos interconectados mediante redes de alta velocidad (Infiniband, Omni-Path). Soportan aplicaciones distribuidas que requieren comunicación intensiva entre nodos, siendo los supercomputadores clústeres de alto rendimiento con características avanzadas de interconexión, memoria y almacenamiento.
\end{itemize}

\section{Portabilidad y reproducibilidad científica}\label{sec:portabilidad_reproducibilidad}

La portabilidad y la reproducibilidad son aspectos fundamentales en la computación científica moderna. La creciente heterogeneidad de plataformas, que abarca desde supercomputadores tradicionales hasta infraestructuras en la nube o clústeres híbridos CPU-GPU, dificulta que una aplicación pueda ejecutarse sin modificaciones en distintos entornos. Además, la reproducibilidad de resultados experimentales se ha convertido en un reto central, ya que incluso pequeñas diferencias en el entorno de ejecución pueden conducir a variaciones significativas en los resultados obtenidos.

En este contexto, la contenerización emerge como una solución tecnológica que no solo aporta ventajas en términos de gestión e infraestructura, sino que también permite garantizar que las aplicaciones sean fácilmente portables y que los experimentos científicos puedan reproducirse bajo condiciones controladas y consistentes.

\subsection{Cómo los contenedores facilitan la portabilidad de aplicaciones \acs{HPC}}

En el contexto de \acs{HPC}, la portabilidad se refiere a la capacidad de ejecutar una misma aplicación en diferentes sistemas de cómputo sin necesidad de modificar su código fuente ni su configuración. Los contenedores facilitan esta portabilidad al encapsular la aplicación junto con todas sus dependencias, incluyendo bibliotecas, compiladores, intérpretes, librerías de comunicación como MPI y entornos de ejecución específicos. De esta manera, se reduce significativamente la fricción que surge cuando un código funciona en un sistema pero falla en otro.

Mediante la creación de una única imagen de contenedor, es posible desplegar la misma aplicación en múltiples entornos, siempre que exista soporte para la tecnología de contenedores utilizada. Esto asegura consistencia entre plataformas, ya que el mismo contenedor puede ejecutarse en distintos sistemas operativos y arquitecturas, minimizando incompatibilidades. Asimismo, disminuye el tiempo de despliegue, ya que los usuarios no necesitan adaptar ni recompilar el software para cada infraestructura, y facilita el acceso a entornos heterogéneos que combinan CPUs y GPUs, donde la gestión de drivers y librerías suele ser crítica. Otro beneficio es la compatibilidad con diversos entornos, desde clusters virtuales autoescalables en la nube hasta infraestructuras \acs{HPC} tradicionales o equipos personales, garantizando un entorno reproducible y consistente \cite{Vaillancourt2020SelfScalingCA}.

Además, el uso de gestores de paquetes como Nix dentro de contenedores permite fijar versiones exactas de bibliotecas y dependencias, asegurando lo que se denomina \textit{pureza funcional}. Esto garantiza que cualquier ejecución posterior del contenedor produzca resultados idénticos, independientemente de la plataforma en la que se ejecute \cite{Vaillancourt2020SelfScalingCA}.

\subsection{Reproducibilidad de experimentos científicos usando contenedores}

La reproducibilidad científica implica que los resultados de un experimento puedan replicarse bajo las mismas condiciones. En computación científica, factores como la evolución de bibliotecas, diferencias entre compiladores o cambios en sistemas operativos suelen comprometer esta reproducibilidad, dificultando la verificación de resultados a lo largo del tiempo.

Los contenedores abordan estos problemas al encapsular no solo el código de la aplicación, sino también todo el contexto de ejecución. De este modo, se puede garantizar que los experimentos se ejecuten en entornos idénticos, independientemente de la infraestructura subyacente. Por ejemplo, mediante tecnologías como Nix dentro de Docker o Singularity, es posible fijar versiones exactas de paquetes y librerías, asegurando reproducibilidad incluso años después \cite{Vaillancourt2020SelfScalingCA}.

Otra ventaja es la transparencia: al compartir la imagen del contenedor junto con el código y los datos, otros investigadores pueden verificar que los resultados se obtuvieron en condiciones equivalentes. Esto facilita también la colaboración eficiente entre equipos distribuidos geográficamente, que pueden trabajar sobre un mismo entorno sin necesidad de configurar individualmente cada sistema.

Asimismo, los contenedores reducen la carga administrativa. El uso de plantillas de contenedores (\textit{Container Template Library - CTL}) permite a los investigadores adaptar construcciones de software a sus necesidades, manteniendo la consistencia y la reproducibilidad sin depender de la intervención de administradores de sistemas \cite{Vaillancourt2020SelfScalingCA}. Además, la metodología de contenerización ofrece escalabilidad y flexibilidad, permitiendo ejecutar los mismos experimentos desde computadoras personales hasta clusters \acs{HPC} o nubes públicas, garantizando que los resultados sigan siendo reproducibles en cualquier infraestructura \cite{Vaillancourt2020SelfScalingCA}.

En conjunto, los contenedores, especialmente cuando se integran con gestores de paquetes como Nix y tecnologías \acs{HPC} como Singularity, proporcionan un marco sólido para asegurar la reproducibilidad de resultados científicos y habilitar la computación científica en entornos diversos de manera eficiente y segura.