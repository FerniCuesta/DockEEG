\chapter{Estado del arte}\label{cap:estado_del_arte}

% [En el estado del arte se necesita hacer un estudio tanto sobre la tecnología que soporta el proyecto como sobre el problema que se aborda en él. Se puede estructurar por secciones y se aconseja utilizar referencias a los documentos e información que se describe aquí.]

% [Como norma general y más en proyectos con carácter investigador, se recomienda añadir un párrafo por cada documento/referencia que estudie del estado del arte, finalizando esta sección con un párrafo explicativo de la novedad/característica que propone, modifica o añade el proyecto sobre dicho estado del arte.]

\section{Computación de alto rendimiento (\acs{HPC})}\label{sec:computacion_alto_rendimiento}

La computación de alto rendimiento (\acs{HPC}, por sus siglas en inglés) se refiere a la práctica de agregar poder de cómputo para lograr un rendimiento mucho mayor que el que se podría obtener con una computadora convencional, con el objetivo de resolver problemas complejos en ciencias, ingeniería o negocios \cite{sravanthi2014hpc}.

\subsubsection{Objetivos principales de HPC}

El propósito fundamental de HPC es acelerar la resolución de problemas complejos, alcanzando resultados en tiempos factibles que de otra manera requerirían semanas o meses. Para ello, HPC se apoya en dos conceptos centrales: \textbf{paralelización} y \textbf{escalabilidad}.

\paragraph{Paralelización}
La paralelización consiste en descomponer un problema en múltiples tareas que puedan ejecutarse simultáneamente en distintos núcleos de procesamiento, ya sean CPUs o GPUs. Este enfoque permite aprovechar todos los recursos del sistema para reducir significativamente el tiempo de ejecución de las aplicaciones. Existen distintos niveles de paralelización:

\begin{itemize}
    \item \textbf{Paralelización a nivel de instrucción}: el procesador ejecuta varias instrucciones de manera simultánea mediante pipelines y unidades vectoriales.
    \item \textbf{Paralelización a nivel de hilo o thread}: diferentes hilos de ejecución procesan tareas concurrentes dentro de un mismo núcleo o CPU.
    \item \textbf{Paralelización a nivel de proceso o nodo}: tareas completas se distribuyen entre múltiples nodos de un clúster, cada uno con su propio conjunto de recursos.
\end{itemize}

\paragraph{Escalabilidad}
La escalabilidad se refiere a la capacidad de un sistema HPC para aumentar su rendimiento al añadir más recursos de cómputo. Se distingue entre:

\begin{itemize}
    \item \textbf{Escalabilidad fuerte}: mejora del tiempo de ejecución de un mismo problema al incrementar el número de recursos.
    \item \textbf{Escalabilidad débil}: capacidad de resolver problemas de mayor tamaño proporcionalmente al incremento de recursos.
\end{itemize}

Lograr buena escalabilidad es crítico, especialmente en clústeres multinodo, donde la comunicación entre nodos y la sincronización de tareas pueden generar cuellos de botella.

\subsubsection{Arquitecturas comunes en HPC}

Los sistemas HPC modernos pueden clasificarse en función de su arquitectura:

\begin{itemize}
    \item \textbf{Sistemas homogéneos}: utilizan múltiples CPUs idénticas interconectadas, lo que simplifica la planificación de tareas pero puede limitar la eficiencia energética.
    \item \textbf{Sistemas heterogéneos}: combinan distintos tipos de núcleos de procesamiento o aceleradores especializados, como GPUs dedicadas, FPGAs o núcleos de eficiencia energética tipo \textit{big.LITTLE}. Estas arquitecturas permiten mejorar el rendimiento por watt y aprovechar al máximo los recursos disponibles, aunque requieren técnicas avanzadas de programación y planificación de tareas.
    \item \textbf{Clústeres y supercomputadores}: integran múltiples nodos interconectados mediante redes de alta velocidad (Infiniband, Omni-Path), soportando aplicaciones distribuidas que requieren comunicación intensiva entre nodos.
\end{itemize}

\subsection{Virtualización vs contenerización}\label{subsec:virtualizacion_contenedores}

La virtualización y la contenerización representan dos enfoques distintos para la abstracción y gestión de recursos computacionales, cuyo propósito es ejecutar aplicaciones de manera aislada del sistema operativo anfitrión. Ambas tecnologías han sido ampliamente utilizadas en entornos de servidores y, más recientemente, en la computación de alto rendimiento (\acs{HPC}), aunque presentan diferencias fundamentales que influyen en el rendimiento, la eficiencia y la portabilidad.

\subsubsection{Máquinas virtuales (VMs)}

Las máquinas virtuales permiten la ejecución de sistemas operativos completos sobre un hipervisor, el cual actúa como intermediario entre el hardware físico y el sistema operativo invitado. Cada VM incorpora su propio kernel, librerías y aplicaciones, proporcionando un aislamiento fuerte respecto al host y a otras VMs.

Entre las ventajas más destacadas se encuentran:
\begin{itemize}
    \item \textbf{Aislamiento robusto}: garantiza una separación completa de procesos y aplicaciones, reduciendo riesgos de interferencia.
    \item \textbf{Compatibilidad multiplataforma}: posibilita ejecutar sistemas operativos diferentes al del host.
    \item \textbf{Seguridad}: el aislamiento a nivel de kernel refuerza la protección frente a vulnerabilidades.
\end{itemize}

Sin embargo, en entornos HPC las VMs presentan ciertas limitaciones:
\begin{itemize}
    \item \textbf{Sobrecarga de recursos}: cada VM requiere un kernel completo y librerías redundantes, incrementando el consumo de memoria y almacenamiento.
    \item \textbf{Overhead de rendimiento}: la capa de virtualización introduce latencias que afectan especialmente a cargas intensivas en cómputo y al acceso a hardware especializado como GPUs.
    \item \textbf{Gestión compleja}: operaciones como la migración, el clonado o la actualización son más costosas en comparación con los contenedores.
\end{itemize}

\subsubsection{Contenedores}

Los contenedores constituyen una forma de virtualización a nivel de sistema operativo. Comparten el kernel del host, pero mantienen un entorno aislado con librerías y dependencias específicas para cada aplicación. Este enfoque reduce significativamente la sobrecarga respecto a las VMs, permitiendo una mayor eficiencia en la ejecución de aplicaciones HPC.

Sus principales ventajas son:
\begin{itemize}
    \item \textbf{Ligereza y eficiencia}: requieren menos recursos al no replicar un sistema operativo completo, lo que disminuye el overhead en tiempo de ejecución.
    \item \textbf{Portabilidad}: las imágenes de contenedores pueden ejecutarse en distintos sistemas operativos y arquitecturas, facilitando la distribución en entornos heterogéneos.
    \item \textbf{Rapidez de despliegue}: iniciar o actualizar contenedores es mucho más ágil que en las VMs.
    \item \textbf{Compatibilidad con bibliotecas y frameworks HPC}: herramientas como Docker, Singularity/Apptainer o Podman permiten empaquetar dependencias científicas y garantizar la reproducibilidad de los experimentos.
\end{itemize}

\subsubsection{Comparativa entre máquinas virtuales y contenedores en HPC}

Diversos estudios han comparado en detalle las diferencias entre la virtualización a nivel de hardware y la virtualización a nivel de sistema operativo. Sharma et al. (2016)~\cite{sharma2016containers} concluyen que los contenedores ofrecen un rendimiento cercano al nativo, con una sobrecarga mínima en cargas de CPU y red (menor al 3\%), mientras que las VMs introducen una latencia mayor en operaciones intensivas de memoria (hasta un 10\%) y presentan un rendimiento significativamente inferior en operaciones de E/S de disco (hasta un 80\% peor que contenedores). En cuanto al aislamiento de recursos, las VMs proporcionan mayor robustez en escenarios de multi-tenencia, especialmente frente a cargas adversarias en CPU y memoria, mientras que los contenedores son más susceptibles a interferencias en estos casos, como se resume en la Tabla~\ref{tab:vm_vs_container}.

Desde el punto de vista de la gestión, los contenedores ofrecen despliegues más rápidos (menos de un segundo frente a decenas de segundos en VMs) y una mayor flexibilidad en la asignación de recursos. Sin embargo, la migración en vivo está más desarrollada en VMs, mientras que en contenedores se encuentra en una etapa menos madura. Asimismo, el desarrollo de software se ve favorecido en los contenedores gracias a la construcción más rápida de imágenes, menor tamaño de almacenamiento y capacidades integradas de control de versiones (Sharma et al., 2016)~\cite{sharma2016containers}.

\begin{table}[ht]
    \centering
    \begin{tabular}{lcc}
        \toprule
        \textbf{Característica}         & \textbf{Máquinas virtuales} & \textbf{Contenedores}        \\
        \midrule
        Aislamiento                     & Completo                    & Parcial (kernel compartido)  \\
        Consumo de recursos             & Alto                        & Bajo                         \\
        Tiempo de arranque              & Largo                       & Corto                        \\
        Portabilidad                    & Alta                        & Muy alta                     \\
        Acceso a hardware especializado & Limitado                    & Directo con soporte adecuado \\
        Mantenimiento y despliegue      & Complejo                    & Simple                       \\
        Rendimiento en CPU              & Casi nativo                 & Casi nativo                  \\
        Rendimiento en memoria          & Degradación $\sim$10\%      & Mejor que VMs                \\
        Rendimiento en E/S de disco     & Hasta 80\% peor             & Cercano a nativo             \\
        \bottomrule
    \end{tabular}
    \caption{Comparativa entre máquinas virtuales y contenedores en entornos HPC, incluyendo resultados de Sharma et al. (2016)~\cite{sharma2016containers}.}
    \label{tab:vm_vs_container}
\end{table}

En entornos HPC, la contenerización se ha consolidado como la opción preferida para aplicaciones que requieren eficiencia, portabilidad y reproducibilidad.

\subsection{Ecosistema de contenedores en HPC}\label{subsec:ecosistema_contenedores}

El ecosistema de contenedores en \acs{HPC} ha experimentado una evolución acelerada en los últimos años, motivado por la necesidad de incrementar la portabilidad, reproducibilidad y facilidad de despliegue de aplicaciones científicas y de ingeniería. Han surgido múltiples tecnologías y frameworks que ofrecen soluciones adaptadas, en mayor o menor medida, a los entornos HPC. Cada uno presenta ventajas, limitaciones y un grado diferente de adopción dentro de la comunidad científica.

\subsubsection{Docker}

Docker es la plataforma de contenedores más extendida a nivel global. Su éxito radica en la posibilidad de empaquetar aplicaciones con todas sus dependencias en imágenes portables, ejecutables en diferentes sistemas operativos y arquitecturas. Entre sus ventajas destacan:

\begin{itemize}
    \item Virtualización ligera y eficiente a nivel de sistema operativo, permitiendo la ejecución rápida de contenedores sin la sobrecarga de máquinas virtuales tradicionales.
    \item Reducción de costos y tiempos de despliegue, al facilitar la creación y reproducción de entornos de software sin necesidad de configuraciones complejas.
    \item Simplificación del despliegue y gestión de aplicaciones, al separar software de la infraestructura y permitir que una imagen esté lista para ejecutar en segundos.
    \item Bajo consumo de recursos y alto rendimiento, compartiendo kernel y bibliotecas del host, con imágenes más pequeñas y arranque mucho más rápido que máquinas virtuales.
    \item Portabilidad extrema, permitiendo mover aplicaciones entre diferentes máquinas Linux de manera consistente.
    \item Aislamiento y seguridad, garantizando que contenedores independientes no interfieran entre sí, y sin dejar archivos residuales tras su eliminación.
    \item Código abierto y gratuito, eliminando la necesidad de licencias comerciales.
    \item Escalabilidad y usabilidad simplificada gracias a la arquitectura de microservicios y soporte para herramientas de orquestación como Kubernetes \cite{Bhatia2017THERT}.
\end{itemize}

No obstante, en entornos HPC su uso está limitado por la necesidad de permisos de root para ejecutar contenedores y las restricciones de seguridad en clústeres multiusuario.

\subsubsection{Podman}

Podman surge como alternativa a Docker y ofrece compatibilidad casi total con sus comandos y formatos de imagen, con un aspecto clave: no requiere privilegios de root para la ejecución de contenedores. Esto lo convierte en una herramienta especialmente atractiva para entornos HPC multiusuario y con fuertes restricciones de seguridad.

Entre sus características más destacadas se incluyen:

\begin{itemize}
    \item \textbf{Modo rootless}: permite ejecutar y construir contenedores sin privilegios administrativos, aislando el entorno del usuario y reduciendo riesgos de escalada de privilegios.
    \item \textbf{Compatibilidad con OCI y múltiple runtime}: soporta los runtimes \texttt{runc} y \texttt{crun}, así como la creación de imágenes compatibles con OCI.
    \item \textbf{Modelo fork-exec sin daemon}: se aproxima a la filosofía HPC al no depender de un demonio central, facilitando la auditoría y el control de recursos.
    \item \textbf{Rendimiento a escala comparable a bare-metal}: en pruebas con aplicaciones reales (LS-DYNA y benchmarks estándar de CPU y memoria), Podman mostró overhead muy bajo (\<2.1\%), comparable al de Singularity \cite{gantikow2020rootless}. Con ajustes adicionales y scripting, Podman puede igualar o incluso superar el rendimiento de ejecuciones bare-metal y del runtime Shifter en NERSC \cite{stephey2022scaling}.
    \item \textbf{Soporte para Pods}: permite agrupar contenedores compartiendo namespaces, facilitando la ejecución de aplicaciones complejas en paralelo.
    \item \textbf{Optimización en HPC a gran escala}: mediante el uso del modo \textit{exec} para MPI, Podman comparte recursos en un mismo contenedor, minimizando overhead de arranque y mejorando el rendimiento en aplicaciones intensivas en metadatos \cite{stephey2022scaling}.
    \item \textbf{Integración con GPU y sistemas HPC avanzados}: soporta hooks OCI y wrappers para configurar librerías, variables de entorno y acceso a interconexiones de alta velocidad, como Cray Slingshot, garantizando rendimiento en entornos heterogéneos \cite{stephey2022scaling}.
    \item \textbf{Gestión de usuarios y almacenamiento}: permite subuid/subgid persistentes y proporciona almacenamiento NVMe local en nodos de login para mejorar tiempos de construcción de imágenes y productividad del usuario \cite{stephey2022scaling}.
\end{itemize}

Gracias a estas capacidades, Podman se posiciona como una alternativa robusta y escalable para la contenerización en HPC. Su modo rootless, rendimiento competitivo y soporte para entornos distribuidos lo convierten en una opción cada vez más valorada en centros de supercomputación y laboratorios de investigación \cite{gantikow2020rootless, stephey2022scaling}.

\subsubsection{Comparativa y adopción en la comunidad científica}

En función de su adopción y casos de uso, destacan los siguientes puntos:

\begin{itemize}
    \item \textbf{Docker}: ampliamente utilizado en desarrollo y pruebas, gracias a su ecosistema maduro, virtualización ligera, portabilidad y eficiencia en recursos \cite{Bhatia2017THERT}.
    \item \textbf{Podman}: cada vez más valorado en HPC, por su ejecución rootless, su rendimiento a escala comparable a bare-metal y su integración con runtimes modernos \cite{gantikow2020rootless, stephey2022scaling}.
\end{itemize}

\subsubsection{Retos principales en la contenerización en HPC}

La computación de alto rendimiento presenta una serie de desafíos que impactan tanto en la eficiencia como en la adopción de tecnologías emergentes como la contenerización. Entre los principales retos identificados se encuentran los siguientes \cite{zhou2022containerisation}:

\begin{itemize}
    \item \textbf{Compatibilidad de software y librerías}: uno de los mayores obstáculos es la incompatibilidad entre librerías del host y del contenedor (por ejemplo, distintas versiones de \textit{glibc} o incompatibilidades en el ABI del kernel), lo que puede provocar fallos o comportamientos inesperados. Asimismo, no todas las imágenes de Docker son directamente portables a otros motores de contenedores utilizados en HPC, debido a la falta de estandarización completa en los hooks de ejecución y la gestión de privilegios.

    \item \textbf{Seguridad}: los contenedores en HPC enfrentan amenazas como la escalada de privilegios, ataques de denegación de servicio (DoS) o fugas de información. Dado que múltiples contenedores comparten el mismo kernel, una vulnerabilidad en uno de ellos puede comprometer la estabilidad del sistema completo. Aunque mecanismos como \textit{cgroups} o los \textit{user namespaces} reducen el riesgo, no lo eliminan por completo, y muchos centros de supercomputación optan por deshabilitar estas características, limitando así el uso de contenedores modernos.

    \item \textbf{Degradación del rendimiento}: la ejecución de aplicaciones en contenedores puede implicar pérdidas de eficiencia, especialmente en el uso de librerías optimizadas para GPUs o interconexiones de alta velocidad (p. ej., InfiniBand). Además, al aumentar el número de procesos MPI en un mismo nodo, los costes de comunicación interna se incrementan, afectando tanto a operaciones punto a punto como colectivas.

    \item \textbf{Limitaciones en la personalización del kernel}: a diferencia de entornos nativos, los contenedores restringen la instalación de módulos de kernel para preservar el aislamiento, lo que impide ajustes específicos de bajo nivel que podrían mejorar el rendimiento en escenarios HPC. Aunque existen propuestas experimentales como \textit{Xcontainer}, estas aún no están maduras para un uso generalizado.
\end{itemize}

Por otro lado, el uso de contenedores en macOS presenta limitaciones importantes en cuanto al acceso y aprovechamiento de la GPU. A diferencia de los entornos Linux, donde es posible habilitar el acceso directo a dispositivos de hardware desde los contenedores, en macOS existen restricciones derivadas de la arquitectura del sistema y de la infraestructura de virtualización utilizada por Docker. Estas limitaciones afectan especialmente a aplicaciones HPC y de inteligencia artificial que requieren aceleración por GPU, dificultando su ejecución eficiente y restringiendo el rendimiento alcanzable en este sistema operativo.

\textbf{Ausencia de soporte para GPU passthrough}: Docker en macOS no permite el acceso directo a la GPU del host debido a la falta de soporte para GPU passthrough en la infraestructura de virtualización de Apple. Esto impide que los contenedores aprovechen la aceleración por hardware de la GPU, lo que limita el rendimiento de aplicaciones que dependen de procesamiento gráfico intensivo o cómputo acelerado.

\textbf{Dependencia de la infraestructura de virtualización de Apple}: Docker en macOS utiliza el framework de virtualización de Apple, el cual no proporciona acceso directo a la GPU. Esta dependencia restringe la capacidad de los contenedores para ejecutar cargas de trabajo que requieren acceso nativo a la GPU, afectando negativamente el rendimiento y la compatibilidad de aplicaciones científicas y de ingeniería.

\textbf{Limitaciones en la aceleración de GPU en contenedores}: Aunque existen alternativas como Vulkan y MoltenVK que permiten cierto grado de aceleración gráfica en contenedores sobre macOS, el rendimiento obtenido es considerablemente inferior al de soluciones nativas en Linux o Windows. Además, la configuración de estas tecnologías suele ser compleja y no garantiza compatibilidad total con todas las aplicaciones.

\textbf{Desafíos en la implementación de soluciones de GPU en contenedores}: Habilitar el acceso a la GPU en contenedores sobre macOS enfrenta desafíos técnicos significativos, principalmente debido a las restricciones impuestas por la infraestructura de virtualización y la ausencia de soporte oficial para GPU passthrough. Esto limita el desarrollo y la ejecución eficiente de aplicaciones HPC y de inteligencia artificial en entornos contenerizados sobre sistemas Apple.

En conjunto, estos retos evidencian que la contenerización en HPC, si bien aporta ventajas en reproducibilidad, portabilidad y flexibilidad, requiere soluciones específicas para gestionar dependencias, garantizar la seguridad en entornos compartidos y mantener la eficiencia en hardware y comunicaciones paralelas. Muchas de estas cuestiones permanecen abiertas y constituyen áreas activas de investigación.

\section{Portabilidad y reproducibilidad científica}\label{sec:portabilidad_reproducibilidad}

La portabilidad y la reproducibilidad son aspectos fundamentales en la computación científica moderna. La creciente heterogeneidad de plataformas, que abarca desde supercomputadores tradicionales hasta infraestructuras en la nube o clústeres híbridos CPU-GPU, dificulta que una aplicación pueda ejecutarse sin modificaciones en distintos entornos. Además, la reproducibilidad de resultados experimentales se ha convertido en un reto central, ya que incluso pequeñas diferencias en el entorno de ejecución pueden conducir a variaciones significativas en los resultados obtenidos.

En este contexto, la contenerización emerge como una solución tecnológica que no solo aporta ventajas en términos de gestión e infraestructura, sino que también permite garantizar que las aplicaciones sean fácilmente portables y que los experimentos científicos puedan reproducirse bajo condiciones controladas y consistentes.

\subsection{Cómo los contenedores facilitan la portabilidad de aplicaciones HPC}

La portabilidad en \acs{HPC} se refiere a la capacidad de ejecutar una misma aplicación en distintos sistemas de cómputo sin necesidad de modificar su código fuente ni su configuración. Los contenedores facilitan esta portabilidad al encapsular la aplicación junto con todas sus dependencias: bibliotecas, compiladores, intérpretes, librerías de comunicación como MPI y entornos de ejecución específicos. Esto reduce la fricción asociada al ``código que funciona en un sistema pero falla en otro".

Los contenedores permiten definir una única imagen que puede ser desplegada en múltiples entornos, siempre que exista soporte para la tecnología de contenedores utilizada. Este enfoque se traduce en:

\begin{itemize}
    \item \textbf{Consistencia entre plataformas}: el mismo contenedor puede ejecutarse en distintos sistemas operativos y arquitecturas, minimizando incompatibilidades.
    \item \textbf{Reducción del tiempo de despliegue}: los usuarios no necesitan adaptar ni recompilar el software para cada infraestructura.
    \item \textbf{Facilitación del acceso a infraestructuras heterogéneas}: especialmente útil en entornos modernos que combinan CPUs y GPUs, donde las dependencias de drivers y librerías suelen ser críticas.
    \item \textbf{Compatibilidad con entornos locales, HPC y nube}: la misma imagen puede ser utilizada en clusters virtuales autoescalables en la nube, infraestructuras HPC tradicionales o equipos personales, asegurando un entorno consistente y reproducible \cite{Vaillancourt2020SelfScalingCA}.
\end{itemize}

Además, el uso de gestores de paquetes como Nix dentro de contenedores permite fijar versiones exactas de bibliotecas y dependencias (\textit{pureza funcional}), asegurando que cualquier ejecución posterior del contenedor produzca resultados idénticos, sin importar la plataforma \cite{Vaillancourt2020SelfScalingCA}.

\subsection{Reproducibilidad de experimentos científicos usando contenedores}

La reproducibilidad científica requiere que los resultados de un experimento puedan replicarse bajo las mismas condiciones. En computación científica, factores como la evolución de bibliotecas, diferencias en compiladores o cambios en sistemas operativos suelen comprometer la reproducibilidad.

Los contenedores abordan estos problemas al capturar no solo el código de la aplicación, sino también el contexto completo de ejecución. Entre los beneficios se incluyen:

\begin{itemize}
    \item \textbf{Versionado del entorno}: mediante tecnologías como Nix dentro de Docker o Singularity, se garantiza que los paquetes y librerías utilizadas en un experimento mantengan versiones fijas, asegurando reproducibilidad extrema incluso años después \cite{Vaillancourt2020SelfScalingCA}.
    \item \textbf{Transparencia}: al compartir la imagen del contenedor junto con código y datos, otros investigadores pueden verificar que los resultados se obtuvieron en condiciones idénticas.
    \item \textbf{Colaboración eficiente}: equipos distribuidos geográficamente pueden trabajar sobre un entorno común sin necesidad de configurar individualmente cada sistema.
    \item \textbf{Reducción de la carga administrativa}: el uso de plantillas de contenedores (\textit{Container Template Library - CTL}) permite a los investigadores modificar construcciones de software según sus necesidades, manteniendo la consistencia y reproducibilidad sin depender de la intervención de administradores de sistemas \cite{Vaillancourt2020SelfScalingCA}.
    \item \textbf{Escalabilidad y flexibilidad}: la misma metodología de contenerización permite escalar recursos según sea necesario, desde computadoras personales hasta clusters HPC y nubes públicas, asegurando consistencia de entorno y resultados reproducibles \cite{Vaillancourt2020SelfScalingCA}.
\end{itemize}

En conjunto, los contenedores, especialmente cuando se integran con gestores de paquetes como Nix y con tecnologías HPC como Singularity, proporcionan un marco sólido para garantizar la reproducibilidad de resultados científicos y habilitar la computación científica en infraestructuras diversas de manera eficiente y segura.

% \section{Evaluación de rendimiento en contenedores}\label{sec:evaluacion_rendimiento}

% \subsection{Overhead de contenedores}
% Se revisa la literatura sobre la sobrecarga que introducen los contenedores en HPC, considerando aspectos como latencia de comunicación, acceso a memoria y rendimiento de CPU/GPU.

% \subsection{Plataformas y arquitecturas}
% Se analiza cómo los contenedores se comportan en diferentes plataformas y arquitecturas, incluyendo Linux, Windows, macOS, x86, ARM y arquitecturas heterogéneas tipo big.LITTLE.

% \section{Comparativa con ejecución nativa}\label{sec:comparativa_nativa}
% Se comparan los resultados de ejecutar aplicaciones HPC de forma nativa versus contenerizada, analizando ventajas y desventajas en términos de rendimiento, portabilidad y facilidad de despliegue.
