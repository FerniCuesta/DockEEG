\chapter{Conclusiones y trabajo futuro}\label{cap:conclusiones}

% [En este capítulo se presentan las conclusiones obtenidas al llevar a cabo el presente trabajo]

\section{Conclusiones}

% [En esta sección se presentan las principales conclusiones del trabajo realizado.]

El presente trabajo ha llevado a cabo un exhaustivo estudio experimental sobre el rendimiento y la escalabilidad de una aplicación de computación paralela y distribuida en distintos entornos y configuraciones, abarcando tanto la ejecución nativa como en contenedores (Docker y Podman), y considerando diferentes sistemas operativos (Ubuntu, Windows, MacOS), arquitecturas (CPU y CPU+GPU), y modos de operación (monoproceso, multiproceso y barrido de hebras). A continuación se resumen las principales conclusiones extraídas del análisis de todos los resultados obtenidos.

Se ha logrado embeber la aplicación \textit{HPMoon} en contenedores Docker y Podman, creando imágenes optimizadas que incluyen todas las dependencias necesarias para su ejecución. Esto ha permitido garantizar la portabilidad y reproducibilidad de los experimentos, facilitando la ejecución en diferentes plataformas sin necesidad de configurar manualmente el entorno. La comparación entre Docker y Podman ha mostrado que ambos sistemas ofrecen un rendimiento similar, con diferencias mínimas en los tiempos de ejecución, lo que confirma que Podman es una alternativa viable a Docker para este tipo de aplicaciones.

Los resultados obtenidos en los experimentos permiten extraer varias conclusiones clave sobre el comportamiento de HPMoon en diferentes entornos y configuraciones. En primer lugar, se observa que el incremento del número de hebras reduce de forma notable el tiempo de ejecución, alcanzando en configuraciones monoproceso eficiencias superiores al 97\% hasta el límite de núcleos físicos disponibles. El punto óptimo de paralelismo suele situarse en torno a las 8 hebras, que coincide con la arquitectura hardware analizada; a partir de ahí, los beneficios adicionales son escasos e incluso pueden aparecer ligeras penalizaciones por sobrecarga.

En cuanto a la ejecución multiproceso, la escalabilidad es efectiva hasta un cierto umbral, generalmente 4 u 8 procesos. Más allá de ese punto, la coordinación y la comunicación entre procesos introducen una sobrecarga que limita los beneficios del paralelismo. De hecho, en algunos escenarios, añadir más procesos puede llegar a empeorar el rendimiento, algo especialmente evidente en configuraciones con GPU o en entornos contenerizados, donde la gestión de recursos compartidos añade complejidad adicional.

Al comparar la ejecución nativa con la realizada en contenedores (Docker y Podman), se aprecia que el uso de contenedores no introduce penalizaciones relevantes: las diferencias suelen ser inferiores al 5\% y, en algunos casos, incluso se obtienen mejoras. Esto confirma la viabilidad de los contenedores como alternativa eficiente para ejecutar aplicaciones paralelas y distribuidas, manteniendo prácticamente el mismo nivel de rendimiento que en ejecución nativa.

En cuanto a los sistemas operativos, el dispositivo en el que se han realizado los experimentos de Ubuntu y Windows es el mismo, lo que permite una comparación directa. En este caso, Ubuntu ofrece de forma consistente los mejores resultados, con diferencias que pueden llegar a ser significativas en configuraciones multiproceso. Ubuntu es conocido por su eficiencia en la gestión de recursos y su optimización para cargas de trabajo intensivas, lo que se refleja en los tiempos de ejecución observados. Windows, aunque también es capaz de aprovechar el paralelismo, muestra un rendimiento inferior en comparación, lo cual puede atribuirse a diferencias en la gestión de hilos y procesos, así como a la sobrecarga inherente del sistema operativo. En el caso de MacOS la comparación no es directa, ya que el hardware es diferente. En este caso se buscaba evaluar la portabilidad y el rendimiento en un entorno distinto, cosa que se ha logrado parcialmente, ya que la falta de soporte para GPU limita las capacidades de paralelismo y aceleración.

La incorporación de GPU se traduce en una aceleración muy notable en escenarios monoproceso o con un bajo número de procesos, con reducciones de tiempo de entre el 80\% y el 88\%. No obstante, su escalabilidad es limitada en entornos distribuidos: al aumentar los procesos, la coordinación y la gestión compartida de la GPU penalizan el rendimiento, llegando incluso a hacer contraproducente su uso en configuraciones de gran tamaño.

De forma general, el análisis de los experimentos permite recomendar como configuración óptima el uso de 8 subpoblaciones y 8 hebras por proceso, lo que asegura un buen equilibrio entre eficiencia y aprovechamiento de recursos sin incurrir en sobrecarga. En configuraciones multiproceso, el número de procesos debe aumentarse con precaución, ya que el beneficio adicional disminuye rápidamente y puede revertirse si se añaden demasiados.

Finalmente, la utilización de contenedores se confirma como una herramienta clave para garantizar la portabilidad y la reproducibilidad de los experimentos. Gracias a ellos, es posible obtener resultados consistentes en diferentes plataformas y simplificar la gestión y el despliegue de entornos complejos de computación paralela y distribuida. Los resultados obtenidos demuestran que la aplicación analizada es capaz de aprovechar eficazmente el paralelismo y la aceleración por GPU en entornos monoproceso, y que la ejecución en contenedores es una alternativa plenamente válida a la ejecución nativa. Sin embargo, la escalabilidad en entornos multiproceso está limitada por la sobrecarga de coordinación y la gestión de recursos, especialmente al utilizar GPU. Estas conclusiones proporcionan una base sólida para la toma de decisiones en el diseño y despliegue de aplicaciones científicas y de ingeniería en entornos heterogéneos

\section{Retos y trabajo futuro}

A partir de los resultados obtenidos y del análisis detallado de los experimentos, se han identificado varios retos abiertos y posibles líneas de trabajo que pueden contribuir a mejorar tanto el rendimiento como la escalabilidad y la aplicabilidad de la solución propuesta.

Uno de los principales desafíos ha sido el poder utilizar la GPU dentro de los contenedores. La solución más sencilla fue en Ubuntu, donde en base a la documentación oficial de Docker y Nvidia, se pudo conseguir. En Windows, la solución fue más compleja, ya que la documentación oficial existente es más limitada. En MacOS, la utilización de GPU está restringida a ciertas versiones de software dentro del contenedor, como puede ser Fedora.

Otro desafío ha sido la limitada escalabilidad observada al aumentar el número de procesos, especialmente en configuraciones con GPU. En este sentido, futuros estudios podrían centrarse en optimizar los mecanismos de comunicación y coordinación entre procesos, explorar alternativas de middleware más eficientes o incluso aplicar técnicas de balanceo dinámico de carga que reduzcan la sobrecarga y permitan aprovechar mejor los recursos distribuidos. Otra línea de trabajo interesante sería la de trabajar a nivel de multinodo, utilizando clústeres reales de computación de alto rendimiento. Esto permitiría validar la solución en entornos productivos y detectar posibles cuellos de botella o limitaciones que no se manifiestan en escenarios locales.

Otro aspecto clave es la gestión avanzada de recursos heterogéneos. La integración eficiente de CPU, GPU y otras posibles aceleradoras sigue siendo un reto, por lo que resulta interesante investigar estrategias inteligentes de asignación de tareas que se adapten dinámicamente a la disponibilidad y características de cada proceso, maximizando así el rendimiento global del sistema.

En lo referente a la automatización y portabilidad de los experimentos, aunque los contenedores ya han demostrado ser eficaces para garantizar reproducibilidad, aún queda margen de mejora. Incorporar herramientas de orquestación como Kubernetes permitiría automatizar de manera más completa el ciclo experimental, desde el despliegue hasta la monitorización y la recolección de resultados.

Asimismo, el rápido avance de las arquitecturas hardware, con nuevas generaciones de GPU, aceleradores especializados y entornos de computación en la nube, abre la puerta a extender este trabajo hacia escenarios emergentes, adaptando la infraestructura para sacar partido de sus capacidades. A ello se suma un aspecto cada vez más relevante: la eficiencia energética. Optimizar el consumo de recursos no solo permitiría reducir costes, sino también avanzar en sostenibilidad, identificando configuraciones que equilibren rendimiento y consumo energético.

Otra línea prometedora consiste en trasladar la metodología y las herramientas desarrolladas a otros problemas científicos o de ingeniería que también requieran computación paralela y distribuida. De esta forma, se ampliaría el alcance y el impacto del trabajo realizado.

Finalmente, se plantea como reto específico la posibilidad de explotar de forma combinada CPU y GPU en sistemas MacOS, especialmente en las nuevas arquitecturas Apple Silicon. Este avance permitiría superar las limitaciones actuales en dicho entorno, mejorando la portabilidad y aprovechando de forma más completa todos los recursos disponibles.

En resumen, aunque los resultados obtenidos confirman la viabilidad de la solución y aportan una base sólida, el camino hacia su mejora y ampliación es amplio. Los retos y líneas futuras aquí descritos ofrecen oportunidades tanto técnicas como aplicadas, que permitirán seguir avanzando en el desarrollo de soluciones más eficientes, portables y sostenibles en el ámbito de la computación paralela y distribuida.
